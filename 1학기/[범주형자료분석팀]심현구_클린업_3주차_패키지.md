week3_package
================
HyunGoo Shim
2023-03-26

문제 1. 데이터를 불러온 후, 데이터의 구조를 파악하세요. 그 후,
데이터에서 각 변수들이 수치형 변수인지, 범주형 변수인지 판단해보고, 그
이유에 대해서 간단히 서술해 주세요.

``` r
#setwd("C:/Users/mrg07/OneDrive/바탕 화면/99shimshim/SKKU/PSAT/week3/week3_package")

data3 <- read.csv("data_3.csv", header = TRUE)
str(data3)
```

    ## 'data.frame':    768 obs. of  9 variables:
    ##  $ Pregnancies: int  6 1 8 1 0 5 3 10 2 8 ...
    ##  $ Glucose    : int  148 85 183 89 137 116 78 115 197 125 ...
    ##  $ BPressure  : int  72 66 64 66 40 74 50 NA 70 96 ...
    ##  $ SThickness : int  35 29 NA 23 35 NA 32 NA 45 NA ...
    ##  $ Insulin    : int  NA NA NA 94 168 NA 88 NA 543 NA ...
    ##  $ BMI        : num  33.6 26.6 23.3 28.1 43.1 25.6 31 35.3 30.5 NA ...
    ##  $ DiabetesPF : num  0.627 0.351 0.672 0.167 2.288 ...
    ##  $ Age        : int  50 31 32 21 33 30 26 29 53 54 ...
    ##  $ Outcome    : int  1 0 1 0 1 0 1 0 1 1 ...

수치형 변수: pregnancies, glucose, bpressure, sthickness, insulin, bmi,
diabetespf, age 범주형 변수: outcome

outcome은 숫자로 되어 있지만 결과가 성공인 지 실패인 지의 이항자료를
나타내는 범주형 변수로 판단된다.

문제 2. 데이터에서 결측치가 존재하는지 확인한 후, 이를 다음과 같이
시각화해주세요.

``` r
sum(is.na(data3))
```

    ## [1] 652

``` r
library(VIM)
```

    ## Warning: 패키지 'VIM'는 R 버전 4.3.1에서 작성되었습니다

    ## 필요한 패키지를 로딩중입니다: colorspace

    ## 필요한 패키지를 로딩중입니다: grid

    ## The legacy packages maptools, rgdal, and rgeos, underpinning the sp package,
    ## which was just loaded, were retired in October 2023.
    ## Please refer to R-spatial evolution reports for details, especially
    ## https://r-spatial.org/r/2023/05/15/evolution4.html.
    ## It may be desirable to make the sf package available;
    ## package maintainers should consider adding sf to Suggests:.

    ## VIM is ready to use.

    ## Suggestions and bug-reports can be submitted at: https://github.com/statistikat/VIM/issues

    ## 
    ## 다음의 패키지를 부착합니다: 'VIM'

    ## The following object is masked from 'package:datasets':
    ## 
    ##     sleep

``` r
aggr(data3, col = c('lavender','lavenderblush'), prop = F, numbers = T, cex.axis = 0.7)
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-2-1.png)<!-- -->

문제 3. 데이터에서 ‘Outcome’ 변수는 추후에 사용할 예정이니 불러온 데이터
셋을 복사한 후에, 복사한 데이터프레임에서 ‘Outcome’ 변수는 제거해주세요.

``` r
data3_copied <- data3
data3_copied <- data3_copied[, -9]
```

문제 4. 데이터에서 발견한 결측치를 보간하기 전, 결측치가 발생한 변수에
대해서 시각화를 통해 다음과 같이 분포를 확인해주세요.

``` r
library(tidyr)
library(ggplot2)
library(dplyr)
```

    ## 
    ## 다음의 패키지를 부착합니다: 'dplyr'

    ## The following objects are masked from 'package:stats':
    ## 
    ##     filter, lag

    ## The following objects are masked from 'package:base':
    ## 
    ##     intersect, setdiff, setequal, union

``` r
data3_copied %>%
  select(BMI, BPressure, Glucose, Insulin, SThickness) %>% 
  gather() %>% 
  ggplot(aes(value, color = key))+
  scale_color_brewer(palette = "Dark2")+
  facet_wrap(~key, scales = "free", ncol = 3)+
  geom_density()+
  theme_classic()+
  theme(legend.position = "none")
```

    ## Warning: Removed 652 rows containing non-finite values (`stat_density()`).

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

문제 5. KNN 알고리즘을 통하여 변수들에서 발생한 결측치를 보간할
예정입니다. 결측치를 KNN 알고리즘을 통하여 보간하고, 보간 후 결측치가
발생했던 변수에 대해 다시 한번 시각화를 진행하고, 시각화 결과를 통해
결측치 보간 전후로 각 변수들의 분포에 차이가 발생하는지 비교해보세요.

``` r
library("VIM")
imputed_data <- VIM::kNN(data3_copied, k = 5, imp_var = FALSE)

imputed_data %>%
  select(BMI, BPressure, Glucose, Insulin, SThickness) %>% 
  gather() %>% 
  ggplot(aes(value, color = key))+
  scale_color_brewer(palette = "Dark2")+
  facet_wrap(~key, scales = "free", ncol = 3)+
  geom_density()+
  theme_classic()+
  theme(legend.position = "none")
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

결측치의 개수가 많았던 Insulin과 SThickness는 분포에 약간의 변화가
보이지만 큰 틀은 유지하고 있다. 반면, 결측치의 개수가 적었던 BMI,
BPressure, Glucose는 분포가 거의 동일하게 유지되고 있음을 확인할 수
있다.

(+ 보너스 문제 1) 문제 4와 5에서 결측치 보간을 진행할 때, 결측치 보간
전후로 결측치가 발생한 변수에 대해서 분포를 다시 확인하였습니다. 이렇게
결측치 보간 전후로 결측치 보간을 진행한 변수에 대해서 분포를 시각화 하는
이유에 대해서 서술해주세요.

다양한 결측치 보간법 중 주어진 데이터에 맞는 보간법을 사용해야 하기
때문이다. 보간법 적용 전후 시각화를 통해 분포에 변화가 큰 지 파악한 후,
분포가 상당히 달라진다면 다른 방법을 적용하는 것을 생각해 보아야 한다.

(+ 보너스 문제 2) 모델 기반의 결측치 보간법은 모델의 특성과 그
하이퍼파라미터에 따라 보간되는 값이 달라지게 됩니다. KNN 알고리즘의
하이퍼파라미터인 K를 조정하면서, K값에 따른 보간 성능을 확인하고, 이에
대해서 해석해보세요.

``` r
imputed_data_k1 <- VIM::kNN(data3_copied, k = 1, imp_var = FALSE)
imputed_data_k11 <- VIM::kNN(data3_copied, k = 11, imp_var = FALSE)
imputed_data_k111 <- VIM::kNN(data3_copied, k = 111, imp_var = FALSE)

imputed_data_k1 %>%
  select(BMI, BPressure, Glucose, Insulin, SThickness) %>% 
  gather() %>% 
  ggplot(aes(value, color = key))+
  scale_color_brewer(palette = "Dark2")+
  facet_wrap(~key, scales = "free", ncol = 3)+
  geom_density()+
  theme_classic()+
  theme(legend.position = "none")
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-6-1.png)<!-- -->

``` r
imputed_data_k11 %>%
  select(BMI, BPressure, Glucose, Insulin, SThickness) %>% 
  gather() %>% 
  ggplot(aes(value, color = key))+
  scale_color_brewer(palette = "Dark2")+
  facet_wrap(~key, scales = "free", ncol = 3)+
  geom_density()+
  theme_classic()+
  theme(legend.position = "none")
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-6-2.png)<!-- -->

``` r
imputed_data_k111 %>%
  select(BMI, BPressure, Glucose, Insulin, SThickness) %>% 
  gather() %>% 
  ggplot(aes(value, color = key))+
  scale_color_brewer(palette = "Dark2")+
  facet_wrap(~key, scales = "free", ncol = 3)+
  geom_density()+
  theme_classic()+
  theme(legend.position = "none")
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-6-3.png)<!-- -->
K값이 1일 때 성능이 좋다고 수학적으로 증명되었다고 한다. 실제로 k값이 1,
11, 111일 때를 비교해 보았을 때 K값이 커질 수록 점점 모양이 어긋나는
것을 확인할 수 있다. K=1일 때와 K=11일 때는 비슷해 보이지만,
SThickness를 비교해 보면 K=1의 그래프가 결측치 보간 전 그래프와 더
유사하다.

문제 6. 결측치 보간 이후에도 결측치가 존재하는지 확인한 후, 이를 다음과
같이 시각화해주세요

``` r
sum(is.na(imputed_data))
```

    ## [1] 0

``` r
aggr(imputed_data, col = c('lavender','lavenderblush'), prop = F, numbers = T, cex.axis = 0.7)
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-7-1.png)<!-- -->

문제 7. 데이터에서 수치형 변수들만을 사용하여, 수치형 변수들 간의
상관관계를 다음과 같은 상관관계 Plot 을 통해 확인해주세요. 그리고 그
결과에 대해서 간단히 해석해주세요.

``` r
library(corrplot)
```

    ## Warning: 패키지 'corrplot'는 R 버전 4.3.1에서 작성되었습니다

    ## corrplot 0.92 loaded

``` r
imputed_data_cor <- cor(imputed_data)
corrplot(imputed_data_cor, method = 'number', diag = F, order = "AOE")
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-8-1.png)<!-- -->

Chapter 2 : Dimension Reduction & Clustering

문제 1. 항상 동일한 결과를 얻기 위하여 Seed를 고정해주세요 (Seed: 3031)

``` r
set.seed(3031)
```

문제 2. 데이터에서 변수들의 scale에 대한 영향을 제거하기 위해서
스케일링을 진행해주세요.

``` r
imputed_scaled <- scale(imputed_data)
imputed_scaled <- as.data.frame(imputed_scaled)
```

문제 3. 요인분석을 진행하기 전, 요인 분석에 대해서 간단히 찾아본 후,
이에 대해서 서술해주세요.

요인분석(Factor Analysis)은 많은 변수들의 상호 관련성을 소수의
요인(factor)으로 추출하여 전체변수들의 공통요인을 찾아내 각 변수가 받는
영향의 정도와 그 집단의 특성을 규명하는 통계분석방법이다. 즉, 실제결과를
초래하게 되는 요인을 찾아냄으로써 목표로 하는 명제를 설명하는 다변량
통계분석방법이다.

요인분석의 목적은 여러 개의 변수들에 내재된 정보를 이용하여 보다 적은
수의 요인으로 압축, 요약하는 데 있다. 일반적인 요인분석의 목적은 다음과
같다.

첫째, 변수들을 축소한다. 여러개의 관련있는 변수들이 하나의 요인으로
묶여짐으로써 많은 변수들이 적은 수의 요인으로 줄어들게 된다.

둘째, 불필요한 변수들을 제거한다. 요인에 포함되지 않거나 포함되더라도
중요도가 낮은 변수를 찾을 수 있으므로 불필요한 변수가 제거된다.

셋째, 변수들의 특성을 파악한다. 관련된 변수들이 묶여져 요인을 이루고
이들 요인들은 상호 독립적인 특성을 가지게 되므로 변수들의 특성을 알 수
있다.

넷째, 측정항목의 타당성(validity)을 평가할 수 있다. 하나의 특성을
측정하기 위해 관측된 변수들은 하나의 요인으로 묶여진다. 따라서, 이같은
특성을 이용하여 묶여지지 않은 변수는 다른 특성을 가진다고 판단한다.
이것으로 그 특성의 측정항목이 타당한가를 평가할 수 있다. 끝으로
요인분석을 통하여 얻어지는 요인점수를 이용하여 회귀분석, 판별분석 및
군집분석 등에 적용할 수 있다.

\#<http://www.rsinfo.co.kr/staticmethod/factor.htm>

추가) PCA랑 비슷해보이는데? 공통점 - 관측된 여러개의 변수들로 부터
소수의 새로운 변수들을 생성한다. - 차원 축소의 방법으로 활용한다.

차이점 - PCA : 변수간의 중요성이 있다. 주로 제1주성분, 제2주성분 등으로
구분된다. 변수간의 순서가 주어진다. - FA : 변수들은 기본적으로 대등한
관계를 갖는다. 어떤것이 더 중요하다는 것이 없다. 변수간의 순서가 없다.

- PCA : 목표 변수를 잘 분류하기 위해 변수들의 선형 결합에 의해 새로운
  변수를 만든다.
- FA : 데이터가 주어지면 이에 대한 가공 인자들을 만들어 인자들간의 선형
  결합으로 표현한다.

\#<https://datacookbook.kr/39>

문제 4. factor=4, rotation=’varimax’로 설정한 후, 요인분석을
진행해주세요.

``` r
library(stats)
factanal(imputed_scaled, factors = 4, rotation = 'varimax')
```

    ## 
    ## Call:
    ## factanal(x = imputed_scaled, factors = 4, rotation = "varimax")
    ## 
    ## Uniquenesses:
    ## Pregnancies     Glucose   BPressure  SThickness     Insulin         BMI 
    ##       0.425       0.446       0.005       0.581       0.329       0.005 
    ##  DiabetesPF         Age 
    ##       0.945       0.429 
    ## 
    ## Loadings:
    ##             Factor1 Factor2 Factor3 Factor4
    ## Pregnancies                  0.755         
    ## Glucose              0.706   0.173   0.131 
    ## BPressure    0.182           0.208   0.957 
    ## SThickness   0.602   0.188   0.115         
    ## Insulin      0.145   0.803                 
    ## BMI          0.971   0.185           0.124 
    ## DiabetesPF   0.115   0.199                 
    ## Age                  0.178   0.715   0.169 
    ## 
    ##                Factor1 Factor2 Factor3 Factor4
    ## SS loadings      1.384   1.288   1.174   0.990
    ## Proportion Var   0.173   0.161   0.147   0.124
    ## Cumulative Var   0.173   0.334   0.481   0.604
    ## 
    ## Test of the hypothesis that 4 factors are sufficient.
    ## The chi square statistic is 2.14 on 2 degrees of freedom.
    ## The p-value is 0.343

문제 5. 문제 4에서 진행한 요인분석을 바탕으로, 다음 문제들을
해결하세요. - Factor=4로 설정하여 진행한 요인 분석이 유의한지
확인해주세요 (변수들을 4개의 factor로 표현하는 것이 유의한가?)

유의하지 않다. DiabetesPF의 loading이 모든 factor에 대해 0.2 이하로,
DiabetesPF가 속할 factor가 존재하지 않는다. 또한 Cumulative Var를 봤을
때 네 요인에 의해 설명되는 변동이 총 변동의 60.4% 밖에 되지 않는다.
Chapter1 7번의 상관관계 plot에서 확인한 것처럼, 상관관계가 높았던 두
변수들이 짝지어져서 한 요인이 될 수 있다. 그렇게 세 요인이 형성되고,
남은 두 변수는 서로 상관관계가 낮기 때문에 각각 따로 보아서, 총 5개의
요인으로 나누는 것이 적당해 보인다.

- Factor 1부터 Factor 4까지의 요인 적재량(Loading)을 확인하고, 각
  Factor들이 변수들에서 어떤 요인을 의미하는지 서술해주세요.

Factor1은 SThickness와 BMI의 요인 적재량이 높다. 따라서 Factor1은
몸무게와 관련 있다고 볼 수 있다. Factor2는 Glucose와 Insulin의 요인
적재량이 높다. 따라서 Factor2는 혈당량과 관련있는 변수다. Factor3는
Pregnancies와 Age의 요인 적재량이 높다. 따라서 Factor3는 임부의 나이라고
할 수 있다. Factor4는 BPressure의 요인 적재량이 높다. 따라서 Factor4는
혈압이라고 볼 수 있다.

- 앞서 확인한 요인 적재량을 기준으로, 해당 Factor를 가장 잘 설명할 수
  있는 변수들을 각 Factor에서 하나씩 선택해주세요.

Factor1: BMI Factor2: Insulin Factor3: Pregnancies Factor4: Bpressure

문제 6. 클러스터링을 위해 데이터에서 ‘BMI’, ‘Glucose’, ‘Age’,
‘BPressure’ 변수만 선택하여 클러스터링용 데이터 셋을 만들어주세요.

``` r
attach(imputed_scaled)
cluster <- cbind(BMI, Glucose, Age, BPressure)
cluster <- as.data.frame(cluster)
detach(imputed_scaled)
```

(+ 보너스 문제 3) 앞서 문제 5에서 선택한 변수와 클러스터링을 위해 선택한
변수가 다르다면, 왜 그 변수들대신 다음과 같은 변수들을 사용하여
클러스터링을 진행하였는지 고민해보고, 그 이유에 대해서 서술해주세요.

인슐린은 글루코스(포도당) 수치를 조절하는 호르몬이므로, 글루코스의
영향을 받는 2차적인 변수라고 할 수 있다. 따라서 loading이 더 낮다고 해도
더 근본적이고 1차적인 변수인 글루코스를 선택하는 편이 낫다.

Pregnancies는 임부의 임신기간을 나타내는 변수로 보인다. 구간이 0\~17밖에
안 되기 때문에 더 넓은 구간을 다룰 수 있는 Age를 선택하는 편이
나아보인다.

문제 7. 클러스터링을 진행하기 전 최적의 클러스터 개수를 정하는 기준이
되는 Within Sum of Square(WSS)와 실루엣 계수(Silhouette Coefficient)가
무엇인지 알아본 후, 간단히 서술해주세요.

within_ss : 같은 군집 내에서의 분산 between_ss : 다른 클러스터 간의 분산
(떨어져 있는 정도) total_ss : 전체 분산 따라서 (between_SS /
total_SS)값이 높을 수록 잘 분류된 군집이다. 우리의 목적은 이 숫자를
높이는데 있다.

- 군집 수가 많아지면 당연히 높아진다. 하지만 무작정 군집수를 높이는 것은
  의미없는 분류가 된다.
- 잘 분류된 군집일수록 within_ss 값은 낮고, between_ss 는 높다

실루엣 계수(Silhouette Coefficient) :

각 데이터 포인트와 주위 데이터 포인트들과의 거리 계산을 통해 값을
구하며, 군집 안에 있는 데이터들은 잘 모여있는지, 군집끼리는 서로 잘
구분되는지 클러스터링을 평가하는 척도로 활용된다. 군집 내
비유사성(‘within’ dissimilarities)은 작고, 군집 간 비유사성(‘between’
dissimilarities)은 커야 생성된 클러스터의 품질이 좋다고 할 수 있다.

실루엣계수가 0에 가까운 경우는, 두 군집 간 거리가 거의 비슷한 경우를
의미하며 잘 구분되지 않은 상태이다. 실루엣계수가 -1에 가까운 경우는,
데이터 포인트 i가 오히려 이웃 클러스터에 더 가까운 경우를 의미하며 아예
잘못 할당된 상태라고 볼 수 있다. 그래서 이러한 경우는 실제로는 거의
나타나지 않는다.

실루엣 분석의 장점

클러스터링이 수행된 후 실제 구분된 클러스터에 따라 실루엣 계수를 구하기
때문에, 클러스터링 알고리즘에 영향을 받지 않는다. 적절한 클러스터 개수를
정하거나 더 나은 클러스터링 기법을 선택하는 기준으로 삼을 수 있다.
클러스터링 결과 값을 시각화할 수 있다.

실루엣 분석의 단점

데이터 양이 많아질수록 수행 시간이 오래 걸린다. 만일 100개의 데이터
포인트가 있다면 99개의 다른 데이터 포인트들과 거리를 구해 실루엣 계수를
구해야 하고, 이런 동일한 연산을 100번 수행해야 한다. 전체 데이터
포인트의 실루엣 계수 평균값만으로 클러스터링 결과를 판단할 수 없으며
개별 클러스터의 평균값도 함께 고려해야 한다.

문제 8. K-means 클러스터링을 진행하기 전 fviz_nbcluster를 활용하여
Within Sum of Square플랏과 Silhouette Coefficient를 다음과 같이 시각화
한 후, 최적의 클러스터 개수를 선정해주세요.

``` r
library(factoextra)
```

    ## Warning: 패키지 'factoextra'는 R 버전 4.3.1에서 작성되었습니다

    ## Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa

``` r
library(gridExtra)
```

    ## 
    ## 다음의 패키지를 부착합니다: 'gridExtra'

    ## The following object is masked from 'package:dplyr':
    ## 
    ##     combine

``` r
plot1 <- fviz_nbclust(cluster, FUNcluster = kmeans, linecolor = "aquamarine4", method = "wss")
plot2 <- fviz_nbclust(cluster, FUNcluster = kmeans, linecolor = "aquamarine4")
grid.arrange(plot1, plot2, nrow = 1)
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-13-1.png)<!-- -->

문제 9. k=3, iter.max=50, nstart=1 로 설정하여 클러스터링을 진행한 후,
다음과 같이 결과를 시각화해주세요.

``` r
set.seed(3031)
result1 <- kmeans(cluster, centers = 3, iter.max = 50, nstart = 1)
fviz_cluster(result1, cluster, geom = "point", main = "K-means result") +
  theme(legend.position = "bottom")
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-14-1.png)<!-- -->

문제 9. Hierarchical 클러스터링 또한 마찬가지로 fviz_nbcluster를
활용하여 Within Sum of Square플랏과 Silhouette Coefficient를 다음과 같이
시각화 한 후, 최적의 클러스터 개수를 선정해주세요.

``` r
plot3 <- fviz_nbclust(cluster, FUNcluster = hcut, linecolor = "aquamarine4", method = "wss")
plot4 <- fviz_nbclust(cluster, FUNcluster = hcut, linecolor = "aquamarine4")
grid.arrange(plot3, plot4, nrow = 1)
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-15-1.png)<!-- -->

기울기가 급변하는 k = 2, 또는 k = 3인 경우로 설정한다.

문제 10. k=3, hc_func=’hclust’로 설정하여 클러스터링을 진행한 후, 다음과
같이 결과를 시각화해주세요.

``` r
set.seed(3031)
result2 <- hcut(x = cluster, k = 3, hc_func = 'hclust')

fviz_cluster(result2, cluster, geom = "point", main = "Hierarchical result") +
  theme(legend.position = "bottom")
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-16-1.png)<!-- -->

문제 11. K-means 클러스터링 결과와 Hierarchical 클러스터링의 실루엣
계수를 다음과 같이 시각화 한 후, 클러스터링 결과(각 데이터들끼리 잘
묶였는지)에 대해서 해석해주세요.

``` r
library(cluster)
```

    ## Warning: 패키지 'cluster'는 R 버전 4.3.1에서 작성되었습니다

``` r
distance <- dist(cluster, method= "euclidean")
sil1 <- silhouette(result1$cluster, dist = distance)
sil2 <- silhouette(result2$cluster, dist = distance)

par(mfrow = c(1, 2))
fviz_silhouette(sil1, print.summary = F)
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-17-1.png)<!-- -->

``` r
fviz_silhouette(sil2, print.summary = F)
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-17-2.png)<!-- -->

실루엣계수가 음수인 값들이 소수 있긴 하지만 대부분의 객체가 양수 값을
가지기 때문에 군집화가 잘 이루어 졌다고 할 수 있다.

문제 12. K-means 클러스터링 결과에서 각 클러스터 별 중심점을 파악하고,
다음과 같이 각 클러스터 별 나이, BMI, 혈압, 글루코스에 대해서 비교하기
위해 박스 플랏을 그려보세요.

``` r
library(scales)
library(RColorBrewer)

result1$centers
```

    ##          BMI    Glucose        Age  BPressure
    ## 1 -0.5337158 -0.5593397 -0.5488273 -0.6497150
    ## 2 -0.1908164  0.7833127  1.3560073  0.4573385
    ## 3  0.8859941  0.2021004 -0.2356669  0.5690786

``` r
result1$cluster <- as.factor(result1$cluster)

mycolor <- brewer.pal(3, "Pastel1")

bxplt_1 <- cluster %>% 
  ggplot(aes(x = result1$cluster, y = Age)) +
  geom_boxplot(show.legend = FALSE, fill = mycolor) +
  xlab("Age") +
  ylab("")
  
bxplt_2 <- cluster %>% 
  ggplot(aes(x = result1$cluster, y = BMI)) +
  geom_boxplot(show.legend = FALSE, fill= mycolor) +
  xlab("BMI") +
  ylab("")

bxplt_3 <- cluster %>% 
  ggplot(aes(x = result1$cluster, y = BPressure)) +
  geom_boxplot(show.legend = FALSE, fill= mycolor) +
  xlab("BPressure") +
  ylab("")

bxplt_4 <- cluster %>% 
  ggplot(aes(x = result1$cluster, y = Glucose)) +
  geom_boxplot(show.legend = FALSE, fill= mycolor) +
  xlab("Glucose") +
  ylab("") +
  scale_fill_brewer(palette = 'Pastel1')

grid.arrange(bxplt_1, bxplt_2, bxplt_3, bxplt_4, nrow = 2, ncol = 2, top = textGrob("K-means 클러스터 별 나이, BMI, 혈압, 글루코스 비교"), left = "value")
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-18-1.png)<!-- -->

문제 13. Hierarchical 클러스터링 결과를 바탕으로 다음과 같이
덴드로그램을 그려보고, 각 클러스터 별 나이, BMI, 혈압, 글루코스에 대해서
비교하기 위해 박스 플랏을 그려보세요.

``` r
fviz_dend(result2, show_labels = FALSE, cex = 0.5, k = 3, color_labels_by_k = FALSE, rect = TRUE, main = "Hierarchical result", main.loc = "middle")
```

    ## Warning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use "none" instead as
    ## of ggplot2 3.3.4.
    ## ℹ The deprecated feature was likely used in the factoextra package.
    ##   Please report the issue at <https://github.com/kassambara/factoextra/issues>.
    ## This warning is displayed once every 8 hours.
    ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
    ## generated.

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-19-1.png)<!-- -->

``` r
result2$cluster <- as.factor(result1$cluster)

bxplt_h1 <- cluster %>% 
  ggplot(aes(x = result2$cluster, y = Age)) +
  geom_boxplot(show.legend = FALSE, fill = mycolor) +
  xlab("Age") +
  ylab("")

bxplt_h2 <- cluster %>% 
  ggplot(aes(x = result2$cluster, y = BMI)) +
  geom_boxplot(show.legend = FALSE, fill = mycolor) +
  xlab("Age") +
  ylab("")

bxplt_h3 <- cluster %>% 
  ggplot(aes(x = result2$cluster, y = BPressure)) +
  geom_boxplot(show.legend = FALSE, fill = mycolor) +
  xlab("Age") +
  ylab("")

bxplt_h4 <- cluster %>% 
  ggplot(aes(x = result2$cluster, y = Glucose)) +
  geom_boxplot(show.legend = FALSE, fill = mycolor) +
  xlab("Age") +
  ylab("")

grid.arrange(bxplt_h1, bxplt_h2, bxplt_h3, bxplt_h4, nrow = 2, ncol = 2, top = textGrob("계층적 클러스터 별 나이, BMI, 혈압, 글루코스 비교"), left = "value")
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-20-1.png)<!-- -->

(+ 보너스 문제 4) 앞서 제거한 “Outcome(실제 당뇨 여부)”와 클러스터링
결과들을 비교하기 위해 다음과 같이 시각화를 진행한 후, 앞서 확인한
클러스터링 결과에 대한 해석과 연관지어서 생각해보세요. (시각화를
진행하지 않고 해석만 해도 괜찮습니다.)

(+ 보너스 문제 5) 고차원에서 진행된 클러스터링 결과를 시각화하기 위해
오늘 사용한 fviz_cluster()는 PCA를 통해 차원축소를 진행한 후, 클러스터링
결과를 2차원으로 표현합니다. 이처럼 클러스터링 결과의 시각화를 위해
사용되는 차원 축소 기법에는 TSNE가 존재합니다. TSNE가 무엇인지에 대해서
살펴보고, Perplexity를 50으로 설정하여 다음과 같이 클러스터링 결과에
대해서 시각화를 진행해보세요.

PCA의 경우 선형 분석 방식으로 값을 사상하기 때문에 차원이 감소되면서
군집화 되어 있는 데이타들이 뭉게져서 제대로 구별할 수 없는 문제를 가지고
있다. 이런 문제를 해결하기 위한 차원 감소 방법으로는 t-SNE (티스니라고
읽음) 방식이 있다.

먼저 점을 하나 선택한다. 아래는 검정색점을 선택했는데, 이 점에서 부터
다른점까지의 거리를 측정한다. 다음 T 분포 그래프를 이용하여, 검정
점(기준점) 을 T 분포 상의 가운데 위치한다면, 기준점으로부터 상대점 까지
거리에 있는 T 분포의 값을 선택(위의 T 분포 그래프에서 파란점에서 위로
점섬이 올라가서 T분포 그래프상에 붉은 색으로 X 표가 되어 있는 값)하여,
이 값을 친밀도 (Similarity)로 하고, 이 친밀도가 가까운 값끼리 묶는다.

이 경우 PCA 처럼 군집이 중복되지 않는 장점은 있지만, 매번 계산할때 마다
축의 위치가 바뀌어서, 다른 모양으로 나타난다. 단 데이타의 군집성과 같은
특성들은 유지 되기 때문에 시각화를 통한 데이타 분석에는 유용하지만, 매번
값이 바뀌는 특성으로 인하여, 머신러닝 모델의 학습 피쳐로 사용하기는 다소
어려운점이 있다.

\#<https://bcho.tistory.com/1210>

``` r
library(Rtsne)
```

    ## Warning: 패키지 'Rtsne'는 R 버전 4.3.1에서 작성되었습니다

``` r
tsne_out <- Rtsne(cluster, perplexity = 50)
tsne_plot <- data.frame(x = tsne_out$Y[,1], y = tsne_out$Y[,2])
ggplot(tsne_plot) +
  geom_point(aes(x=x,y=y))
```

![](%5B범주형자료분석팀%5D심현구_클린업_3주차_패키지_files/figure-gfm/unnamed-chunk-21-1.png)<!-- -->
